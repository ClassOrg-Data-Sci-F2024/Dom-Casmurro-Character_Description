---
title: "Final Project - Dom Casmurro"
author: "LUIZA DIVINO"
date: "2024-10-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Goal
Verify how Capitu and Escobar are described throughout the story, making a comparison between how they were portrayed by Bentinho before and after the apparent adultery

## Steps

- Load all the packages that will be needed for the analysis

- Import data: PDF

- Convert data to tibble

- Tokenize data: devide it into words

- Create columns: `word` and `page`

- Lowercase data

- Add stop wordlist without common words (https://gist.github.com/alopes/5358189) and create new dataset


### Load packages
```{r}
library(tidyverse)
library(tidytext)
library(pdftools)
library(tibble)
library (stringr)
```

### Import data

The data is in PDF format, so first it is necessary to read the PDF file using `pdf_text`.
```{r}
dom_casmurro_pdf <- pdf_text("/Users/luizadivino/Downloads/domCasmurro.pdf")

# use cat to have a preview of the first page
cat(dom_casmurro_pdf[1])
```

Change format so that it is possible to access the data. Transforming the pdf to tibble separates the whole content in each page as if they were one single value. For it to be possible to analyse the data, it is necessary to tokenize the corpus word by word, making it possible to access in which page each word is located. This will leave us with two variables: `page` and `words`.

Before going through this process, there were 128 observations (the book has 128 pages). The tokenization leaves us with 669267 observations, which represents the total number of words in the book, elements like "Chapter" and so on.
```{r}
# data transformation
dom_casmurro_tibble <- tibble(page = 1:length(dom_casmurro_pdf), text = dom_casmurro_pdf)

# data tokenization
dom_casmurro_tidy_text <- dom_casmurro_tibble %>%
  unnest_tokens(word, text)

# naming the columns "page" and "word" for them to match the names of the columns on the stop wordlist

colnames(dom_casmurro_tidy_text) <- c("page", "word")
```







